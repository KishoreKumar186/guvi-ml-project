{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I've created a text file with all the code sections clearly marked with === SECTION NAME === separators. Each section includes both the markdown cells and code cells, making it easy for you to copy and paste them into your Jupyter notebook. The sections are organized as follows:\n",
    "Title and Introduction\n",
    "Part 1: Data Exploration and Preprocessing\n",
    "Imports\n",
    "Load Data\n",
    "Text Preprocessing\n",
    "Create Labels\n",
    "Part 2: Model Implementation\n",
    "Dataset Class\n",
    "Data Preparation\n",
    "Model Training\n",
    "Model Evaluation\n",
    "Part 3: Model Deployment\n",
    "Save Model\n",
    "API Deployment\n",
    "Part 4: Summary and Conclusions\n",
    "You can now create a new Jupyter notebook and copy each section between the markers into separate cells. For sections marked with === MARKDOWN: ===, create markdown cells, and for sections marked with === CODE: ===, create code cells.\n",
    "\n",
    "\n",
    "=== MARKDOWN: TITLE ===\n",
    "# Customer Support Ticket Classification - Implementation\n",
    "\n",
    "This notebook demonstrates the implementation of our multi-label classification model for customer support tickets.\n",
    "\n",
    "=== MARKDOWN: PART 1 ===\n",
    "## Part 1: Data Exploration and Preprocessing\n",
    "\n",
    "=== CODE: IMPORTS ===\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "=== MARKDOWN: LOAD DATA ===\n",
    "### 1.1 Load and Examine Data\n",
    "\n",
    "=== CODE: LOAD DATA ===\n",
    "# Load the dataset\n",
    "df = pd.read_json('data/electronics_reviews.json', lines=True)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nSample Data:\")\n",
    "df.head()\n",
    "\n",
    "=== MARKDOWN: TEXT PREPROCESSING ===\n",
    "### 1.2 Text Preprocessing\n",
    "\n",
    "=== CODE: TEXT PREPROCESSING ===\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and normalize text data.\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Combine review text and summary\n",
    "df['combined_text'] = df['reviewText'] + ' ' + df['summary']\n",
    "\n",
    "# Clean text\n",
    "df['combined_text'] = df['combined_text'].apply(preprocess_text)\n",
    "\n",
    "# Display sample of preprocessed text\n",
    "print(\"Sample of preprocessed text:\")\n",
    "print(df['combined_text'].iloc[0])\n",
    "\n",
    "=== MARKDOWN: CREATE LABELS ===\n",
    "### 1.3 Create Multi-Label Categories\n",
    "\n",
    "=== CODE: CREATE LABELS ===\n",
    "def create_labels(df):\n",
    "    \"\"\"Create multi-label categories based on review content with 10 categories.\"\"\"\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        review = row['combined_text'].lower()\n",
    "        label = [0] * 10  # 10 categories\n",
    "        \n",
    "        # Product Quality\n",
    "        if any(word in review for word in ['quality', 'durable', 'reliable', 'broken', 'defect']):\n",
    "            label[0] = 1\n",
    "            \n",
    "        # Customer Service\n",
    "        if any(word in review for word in ['service', 'support', 'help', 'customer', 'return']):\n",
    "            label[1] = 1\n",
    "            \n",
    "        # Price\n",
    "        if any(word in review for word in ['price', 'cost', 'expensive', 'cheap', 'value']):\n",
    "            label[2] = 1\n",
    "            \n",
    "        # Functionality\n",
    "        if any(word in review for word in ['work', 'function', 'feature', 'performance']):\n",
    "            label[3] = 1\n",
    "            \n",
    "        # Technical Issues\n",
    "        if any(word in review for word in ['bug', 'error', 'crash', 'glitch', 'problem']):\n",
    "            label[4] = 1\n",
    "            \n",
    "        # Shipping/Delivery\n",
    "        if any(word in review for word in ['shipping', 'delivery', 'arrived', 'package']):\n",
    "            label[5] = 1\n",
    "            \n",
    "        # User Experience\n",
    "        if any(word in review for word in ['easy', 'difficult', 'simple', 'complicated']):\n",
    "            label[6] = 1\n",
    "            \n",
    "        # Product Compatibility\n",
    "        if any(word in review for word in ['compatible', 'compatibility', 'works with']):\n",
    "            label[7] = 1\n",
    "            \n",
    "        # Product Features\n",
    "        if any(word in review for word in ['feature', 'specification', 'capability']):\n",
    "            label[8] = 1\n",
    "            \n",
    "        # Others\n",
    "        if sum(label) == 0:\n",
    "            label[9] = 1\n",
    "            \n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(labels)\n",
    "\n",
    "# Create labels\n",
    "labels = create_labels(df)\n",
    "\n",
    "# Create DataFrame for labels\n",
    "labels_df = pd.DataFrame(labels, columns=[\n",
    "    'Product Quality', 'Customer Service', 'Price', 'Functionality',\n",
    "    'Technical Issues', 'Shipping/Delivery', 'User Experience',\n",
    "    'Product Compatibility', 'Product Features', 'Others'\n",
    "])\n",
    "\n",
    "# Display label distribution\n",
    "print(\"Label Distribution:\")\n",
    "print(labels_df.sum())\n",
    "\n",
    "=== MARKDOWN: PART 2 ===\n",
    "## Part 2: Model Implementation\n",
    "\n",
    "=== MARKDOWN: DATASET CLASS ===\n",
    "### 2.1 Create Custom Dataset Class\n",
    "\n",
    "=== CODE: DATASET CLASS ===\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.FloatTensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "=== MARKDOWN: DATA PREPARATION ===\n",
    "### 2.2 Prepare Data for Training\n",
    "\n",
    "=== CODE: DATA PREPARATION ===\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['combined_text'], labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Handle class imbalance\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(\n",
    "    X_train.values.reshape(-1, 1), y_train\n",
    ")\n",
    "X_train_resampled = X_train_resampled.flatten()\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ReviewDataset(X_train_resampled, y_train_resampled, tokenizer)\n",
    "test_dataset = ReviewDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")\n",
    "\n",
    "=== MARKDOWN: MODEL TRAINING ===\n",
    "### 2.3 Model Training\n",
    "\n",
    "=== CODE: MODEL TRAINING ===\n",
    "def train_model(model, train_loader, val_loader, device, num_epochs=3):\n",
    "    \"\"\"Train the BERT model.\"\"\"\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs.logits, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}:')\n",
    "        print(f'Training Loss: {total_loss/len(train_loader):.4f}')\n",
    "        print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "\n",
    "# Initialize model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=10,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "train_model(model, train_loader, test_loader, device)\n",
    "\n",
    "=== MARKDOWN: MODEL EVALUATION ===\n",
    "### 2.4 Model Evaluation\n",
    "\n",
    "=== CODE: MODEL EVALUATION ===\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate the model using various metrics.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.sigmoid(outputs.logits)\n",
    "            preds = (preds > 0.5).float()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    hamming = hamming_loss(all_labels, all_preds)\n",
    "    subset_acc = accuracy_score(all_labels, all_preds)\n",
    "    micro_f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    # Calculate AUC-ROC for each category\n",
    "    category_names = [\n",
    "        'Product Quality', 'Customer Service', 'Price', 'Functionality',\n",
    "        'Technical Issues', 'Shipping/Delivery', 'User Experience',\n",
    "        'Product Compatibility', 'Product Features', 'Others'\n",
    "    ]\n",
    "    \n",
    "    auc_scores = []\n",
    "    for i in range(all_labels.shape[1]):\n",
    "        auc = roc_auc_score(all_labels[:, i], all_preds[:, i])\n",
    "        auc_scores.append((category_names[i], auc))\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        'hamming_loss': hamming,\n",
    "        'subset_accuracy': subset_acc,\n",
    "        'micro_f1': micro_f1,\n",
    "        'macro_f1': macro_f1,\n",
    "        'auc_scores': dict(auc_scores),\n",
    "        'inference_time': inference_time\n",
    "    }\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Evaluating model...\")\n",
    "metrics = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(f\"Hamming Loss: {metrics['hamming_loss']:.4f}\")\n",
    "print(f\"Subset Accuracy: {metrics['subset_accuracy']:.4f}\")\n",
    "print(f\"Micro F1 Score: {metrics['micro_f1']:.4f}\")\n",
    "print(f\"Macro F1 Score: {metrics['macro_f1']:.4f}\")\n",
    "print(\"\\nAUC-ROC Scores for each category:\")\n",
    "for category, score in metrics['auc_scores'].items():\n",
    "    print(f\"{category}: {score:.4f}\")\n",
    "print(f\"\\nInference Time: {metrics['inference_time']:.2f} seconds\")\n",
    "\n",
    "=== MARKDOWN: PART 3 ===\n",
    "## Part 3: Model Deployment\n",
    "\n",
    "=== MARKDOWN: SAVE MODEL ===\n",
    "### 3.1 Save the Model\n",
    "\n",
    "=== CODE: SAVE MODEL ===\n",
    "# Save the model\n",
    "model.save_pretrained('trained_model')\n",
    "tokenizer.save_pretrained('trained_model')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "=== MARKDOWN: API DEPLOYMENT ===\n",
    "### 3.2 Create API for Model Deployment\n",
    "\n",
    "=== CODE: API DEPLOYMENT ===\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class PredictionRequest(BaseModel):\n",
    "    text: str\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    categories: dict\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(request: PredictionRequest):\n",
    "    try:\n",
    "        # Preprocess text\n",
    "        text = preprocess_text(request.text)\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predictions = torch.sigmoid(outputs.logits)\n",
    "            predictions = (predictions > 0.5).float()\n",
    "        \n",
    "        # Create response\n",
    "        category_names = [\n",
    "            'Product Quality', 'Customer Service', 'Price', 'Functionality',\n",
    "            'Technical Issues', 'Shipping/Delivery', 'User Experience',\n",
    "            'Product Compatibility', 'Product Features', 'Others'\n",
    "        ]\n",
    "        \n",
    "        result = {\n",
    "            category_names[i]: bool(predictions[0][i])\n",
    "            for i in range(len(category_names))\n",
    "        }\n",
    "        \n",
    "        return {\"categories\": result}\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Run the API (in a separate cell)\n",
    "# uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "=== MARKDOWN: SUMMARY ===\n",
    "## Part 4: Summary and Conclusions\n",
    "\n",
    "### 4.1 Project Summary\n",
    "\n",
    "1. **Data Processing**:\n",
    "   - Loaded and preprocessed Amazon Electronics Reviews\n",
    "   - Created 10 multi-label categories\n",
    "   - Handled class imbalance using RandomOverSampler\n",
    "\n",
    "2. **Model Development**:\n",
    "   - Fine-tuned BERT for multi-label classification\n",
    "   - Implemented custom dataset class\n",
    "   - Added evaluation metrics\n",
    "\n",
    "3. **Deployment**:\n",
    "   - Created FastAPI for model serving\n",
    "   - Added error handling\n",
    "   - Implemented prediction endpoint\n",
    "\n",
    "### 4.2 Future Improvements\n",
    "\n",
    "1. **Model Enhancements**:\n",
    "   - Implement data augmentation\n",
    "   - Create ensemble model\n",
    "   - Fine-tune hyperparameters\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Add more category keywords\n",
    "   - Implement advanced text preprocessing\n",
    "   - Add sentiment analysis\n",
    "\n",
    "3. **Deployment**:\n",
    "   - Add authentication\n",
    "   - Implement rate limiting\n",
    "   - Add monitoring and logging "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
